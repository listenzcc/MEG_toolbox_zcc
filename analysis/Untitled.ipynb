{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Importing\n",
    "# System\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Computing\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from surfer import Brain\n",
    "from mayavi import mlab\n",
    "\n",
    "__file__ = os.path.curdir\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'tools'))  # noqa\n",
    "from MEG_worker import MEG_Worker\n",
    "from visualizer import Visualizer\n",
    "from inverse_solver import Inverse_Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 files that ends with _ica-raw.fif\n",
      ">> Got <Raw | block_07_ica-raw.fif, 409 x 2355552 (1963.0 s), ~1017 kB, data not loaded> from ['/home/zcc/RSVP_dataset/processed_data/MEG_S03/block_07_ica-raw.fif', '/home/zcc/RSVP_dataset/processed_data/MEG_S03/block_08_ica-raw.fif', '/home/zcc/RSVP_dataset/processed_data/MEG_S03/block_09_ica-raw.fif', '/home/zcc/RSVP_dataset/processed_data/MEG_S03/block_10_ica-raw.fif', '/home/zcc/RSVP_dataset/processed_data/MEG_S03/block_05_ica-raw.fif', '/home/zcc/RSVP_dataset/processed_data/MEG_S03/block_03_ica-raw.fif', '/home/zcc/RSVP_dataset/processed_data/MEG_S03/block_06_ica-raw.fif', '/home/zcc/RSVP_dataset/processed_data/MEG_S03/block_04_ica-raw.fif']\n",
      "Reading /home/zcc/RSVP_dataset/memory/MEG_S03-U07-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...    1200.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "3688 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      ">> Raw epochs are recalled from memory: <EpochsFIF  |   3688 events (all good), -0.2 - 1.2 sec, baseline off, ~1.05 GB, data loaded,\n",
      " '1': 448\n",
      " '2': 2865\n",
      " '3': 375>\n",
      "Reading /home/zcc/RSVP_dataset/memory/MEG_S03-U07-denoise-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...    1200.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "3688 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      ">> Denoise epochs are recalled from memory: <EpochsFIF  |   3688 events (all good), -0.2 - 1.2 sec, baseline [-0.2, 0], ~1.05 GB, data loaded,\n",
      " '1': 448\n",
      " '2': 2865\n",
      " '3': 375>\n",
      "Reading /home/zcc/RSVP_dataset/memory/MEG_S03-U07-clean-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...    1200.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "448 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      ">> Clean epochs are recalled from memory: <EpochsFIF  |   448 events (all good), -0.2 - 1.2 sec, baseline [-0.2, 0], ~131.6 MB, data loaded,\n",
      " '1': 448>\n",
      "Inversing on RSVP_MRI_S03\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    3 BEM surfaces found\n",
      "    Reading a surface...\n",
      "[done]\n",
      "    Reading a surface...\n",
      "[done]\n",
      "    Reading a surface...\n",
      "[done]\n",
      "    3 BEM surfaces read\n",
      "Loading surfaces...\n",
      "Three-layer model surfaces loaded.\n",
      "\n",
      "Loading the solution matrix...\n",
      "\n",
      "Loaded linear_collocation BEM solution from /home/zcc/RSVP_dataset/processed_data/MEG_S03/RSVP_MRI_S03-bem-sol.fif\n",
      "Reading inverse operator decomposition from /home/zcc/RSVP_dataset/memory/RSVP_MRI_S03-inv.fif...\n",
      "    Reading inverse operator info...\n",
      "    [done]\n",
      "    Reading inverse operator decomposition...\n",
      "    [done]\n",
      "    272 x 272 full covariance (kind = 1) found.\n",
      "    Noise covariance matrix read.\n",
      "    24588 x 24588 diagonal covariance (kind = 2) found.\n",
      "    Source covariance matrix read.\n",
      "    24588 x 24588 diagonal covariance (kind = 6) found.\n",
      "    Orientation priors read.\n",
      "    24588 x 24588 diagonal covariance (kind = 5) found.\n",
      "    Depth priors read.\n",
      "    Did not find the desired covariance matrix (kind = 3)\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Source spaces transformed to the inverse solution coordinate frame\n",
      "Inverse operator is recalled: <InverseOperator | MEG channels: 272 | EEG channels: 0 | Source space: surface with 8196 sources | Source orientation: Free>\n",
      "Write inverse operator decomposition in /home/zcc/RSVP_dataset/memory/RSVP_MRI_S03-inv.fif...\n",
      "    Write a source space...\n",
      "    [done]\n",
      "    Write a source space...\n",
      "    [done]\n",
      "    2 source spaces written\n",
      "    Writing inverse operator info...\n",
      "    Writing noise covariance matrix.\n",
      "    Writing source covariance matrix.\n",
      "    Writing orientation priors.\n",
      "    [done]\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 448\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 6 (266 small eigenvalues omitted)\n",
      "    Computing noise-normalization factors (dSPM)...\n",
      "[done]\n",
      "Applying inverse operator to \"1\"...\n",
      "    Picked 272 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  95.5% variance\n",
      "    Combining the current components...\n",
      "    dSPM...\n",
      "[done]\n",
      "Estimated stc: <SourceEstimate  |  8196 vertices, subject : RSVP_MRI_S03, tmin : -200.0 (ms), tmax : 1200.0000000000002 (ms), tstep : 10.0 (ms), data shape : (8196, 141)>\n",
      "Estimated morphed stc: <SourceEstimate  |  81924 vertices, subject : fsaverage, tmin : -200.0 (ms), tmax : 1200.0000000000002 (ms), tstep : 10.0 (ms), data shape : (81924, 141)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<SourceEstimate  |  8196 vertices, subject : RSVP_MRI_S03, tmin : -200.0 (ms), tmax : 1200.0000000000002 (ms), tstep : 10.0 (ms), data shape : (8196, 141)>,\n",
       " <SourceEstimate  |  81924 vertices, subject : fsaverage, tmin : -200.0 (ms), tmax : 1200.0000000000002 (ms), tstep : 10.0 (ms), data shape : (81924, 141)>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# for idx in range(1, 11):\n",
    "\n",
    "idx = 3\n",
    "running_name = f'MEG_S{idx:02d}'\n",
    "band_name = 'U07'\n",
    "\n",
    "worker = MEG_Worker(running_name=running_name)\n",
    "worker.pipeline(band_name=band_name)\n",
    "\n",
    "# %%\n",
    "# epochs = worker.denoise_epochs['3']\n",
    "epochs = worker.clean_epochs\n",
    "solver = Inverse_Solver(running_name=running_name)\n",
    "solver.pipeline(epochs=epochs,\n",
    "                raw_info=worker.raw.info)\n",
    "\n",
    "# %%\n",
    "stc, stc_fsaverage = solver.estimate(obj=epochs.average())\n",
    "stc, stc_fsaverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method add_annotation in module surfer.viz:\n",
      "\n",
      "add_annotation(annot, borders=True, alpha=1, hemi=None, remove_existing=True, color=None, **kwargs) method of surfer.viz.Brain instance\n",
      "    Add an annotation file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    annot : str | tuple\n",
      "        Either path to annotation file or annotation name. Alternatively,\n",
      "        the annotation can be specified as a ``(labels, ctab)`` tuple per\n",
      "        hemisphere, i.e. ``annot=(labels, ctab)`` for a single hemisphere\n",
      "        or ``annot=((lh_labels, lh_ctab), (rh_labels, rh_ctab))`` for both\n",
      "        hemispheres. ``labels`` and ``ctab`` should be arrays as returned\n",
      "        by :func:`nibabel.freesurfer.io.read_annot`.\n",
      "    borders : bool | int\n",
      "        Show only label borders. If int, specify the number of steps\n",
      "        (away from the true border) along the cortical mesh to include\n",
      "        as part of the border definition.\n",
      "    alpha : float in [0, 1]\n",
      "        Alpha level to control opacity.\n",
      "    hemi : str | None\n",
      "        If None, it is assumed to belong to the hemipshere being\n",
      "        shown. If two hemispheres are being shown, data must exist\n",
      "        for both hemispheres.\n",
      "    remove_existing : bool\n",
      "        If True (default), remove old annotations.\n",
      "    color : matplotlib-style color code\n",
      "        If used, show all annotations in the same (specified) color.\n",
      "        Probably useful only when showing annotation borders.\n",
      "    **kwargs : additional keyword arguments\n",
      "        These are passed to the underlying\n",
      "        ``mayavi.mlab.pipeline.surface`` call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(brain.add_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels from parcellation...\n",
      "   read 16 labels from /nfs/diskstation/zccdata/freesurfer/subjects/fsaverage/label/lh.PALS_B12_Visuotopic.annot\n",
      "   read 27 labels from /nfs/diskstation/zccdata/freesurfer/subjects/fsaverage/label/rh.PALS_B12_Visuotopic.annot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Visuotopic.LO-lh': <Label  |  fsaverage, 'Visuotopic.LO-lh', lh : 1015 vertices>,\n",
       " 'Visuotopic.LO-rh': <Label  |  fsaverage, 'Visuotopic.LO-rh', rh : 1021 vertices>,\n",
       " 'Visuotopic.MTplus-lh': <Label  |  fsaverage, 'Visuotopic.MTplus-lh', lh : 930 vertices>,\n",
       " 'Visuotopic.MTplus-rh': <Label  |  fsaverage, 'Visuotopic.MTplus-rh', rh : 955 vertices>,\n",
       " 'Visuotopic.V1d-lh': <Label  |  fsaverage, 'Visuotopic.V1d-lh', lh : 4063 vertices>,\n",
       " 'Visuotopic.V1d-rh': <Label  |  fsaverage, 'Visuotopic.V1d-rh', rh : 3506 vertices>,\n",
       " 'Visuotopic.V1v-lh': <Label  |  fsaverage, 'Visuotopic.V1v-lh', lh : 4063 vertices>,\n",
       " 'Visuotopic.V1v-rh': <Label  |  fsaverage, 'Visuotopic.V1v-rh', rh : 3506 vertices>,\n",
       " 'Visuotopic.V2d-lh': <Label  |  fsaverage, 'Visuotopic.V2d-lh', lh : 1888 vertices>,\n",
       " 'Visuotopic.V2d-rh': <Label  |  fsaverage, 'Visuotopic.V2d-rh', rh : 1867 vertices>,\n",
       " 'Visuotopic.V2v-lh': <Label  |  fsaverage, 'Visuotopic.V2v-lh', lh : 1888 vertices>,\n",
       " 'Visuotopic.V2v-rh': <Label  |  fsaverage, 'Visuotopic.V2v-rh', rh : 1867 vertices>,\n",
       " 'Visuotopic.V3-lh': <Label  |  fsaverage, 'Visuotopic.V3-lh', lh : 575 vertices>,\n",
       " 'Visuotopic.V3-rh': <Label  |  fsaverage, 'Visuotopic.V3-rh', rh : 774 vertices>,\n",
       " 'Visuotopic.V3A-lh': <Label  |  fsaverage, 'Visuotopic.V3A-lh', lh : 737 vertices>,\n",
       " 'Visuotopic.V3A-rh': <Label  |  fsaverage, 'Visuotopic.V3A-rh', rh : 882 vertices>,\n",
       " 'Visuotopic.V4v-lh': <Label  |  fsaverage, 'Visuotopic.V4v-lh', lh : 1030 vertices>,\n",
       " 'Visuotopic.V4v-rh': <Label  |  fsaverage, 'Visuotopic.V4v-rh', rh : 860 vertices>,\n",
       " 'Visuotopic.V7-lh': <Label  |  fsaverage, 'Visuotopic.V7-lh', lh : 796 vertices>,\n",
       " 'Visuotopic.V7-rh': <Label  |  fsaverage, 'Visuotopic.V7-rh', rh : 621 vertices>,\n",
       " 'Visuotopic.V8-lh': <Label  |  fsaverage, 'Visuotopic.V8-lh', lh : 881 vertices>,\n",
       " 'Visuotopic.V8-rh': <Label  |  fsaverage, 'Visuotopic.V8-rh', rh : 1246 vertices>,\n",
       " 'Visuotopic.VP-lh': <Label  |  fsaverage, 'Visuotopic.VP-lh', lh : 1177 vertices>,\n",
       " 'Visuotopic.VP-rh': <Label  |  fsaverage, 'Visuotopic.VP-rh', rh : 1237 vertices>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "mne.viz.set_3d_backend('pyvista')\n",
    "\n",
    "label_name = 'PALS_B12_Visuotopic'\n",
    "# labels = mne.read_labels_from_annot('fsaverage', 'aparc', 'both')\n",
    "label_list = mne.read_labels_from_annot('fsaverage', label_name, 'both')\n",
    "labels = dict()\n",
    "for j, label in enumerate(label_list):\n",
    "    if label.name.startswith('Visuotopic'):\n",
    "        labels[label.name] = label\n",
    "display(labels)\n",
    "\n",
    "brain = Brain(subject_id='fsaverage',\n",
    "              hemi='split',\n",
    "              surf='inflated',\n",
    "              cortex='low_contrast',\n",
    "              background='white',\n",
    "              size=(800, 600))\n",
    "# brain.add_annotation('aparc')\n",
    "# brain.add_annotation(label_name)\n",
    "for name in labels:\n",
    "    brain.add_label(labels[name], borders=True)\n",
    "\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visuotopic.LO-lh\n",
      "Visuotopic.LO-rh\n",
      "Visuotopic.MTplus-lh\n",
      "Visuotopic.MTplus-rh\n",
      "Visuotopic.V1d-lh\n",
      "Visuotopic.V1d-rh\n",
      "Visuotopic.V1v-lh\n",
      "Visuotopic.V1v-rh\n",
      "Visuotopic.V2d-lh\n",
      "Visuotopic.V2d-rh\n",
      "Visuotopic.V2v-lh\n",
      "Visuotopic.V2v-rh\n",
      "Visuotopic.V3-lh\n",
      "Visuotopic.V3-rh\n",
      "Visuotopic.V3A-lh\n",
      "Visuotopic.V3A-rh\n",
      "Visuotopic.V4v-lh\n",
      "Visuotopic.V4v-rh\n",
      "Visuotopic.V7-lh\n",
      "Visuotopic.V7-rh\n",
      "Visuotopic.V8-lh\n",
      "Visuotopic.V8-rh\n",
      "Visuotopic.VP-lh\n",
      "Visuotopic.VP-rh\n"
     ]
    }
   ],
   "source": [
    "alldata = sorted(stc_fsaverage.data.ravel(), reverse=True)\n",
    "n = len(alldata)\n",
    "surfer_kwargs = dict(hemi='both',\n",
    "                     clim=dict(kind='value',\n",
    "                               lims=[alldata[int(n * r)] for r in [0.05, 0.01, 0]]),\n",
    "                     views='lateral',\n",
    "                     initial_time=0.4,\n",
    "                     time_unit='s',\n",
    "                     size=(800, 800),\n",
    "                     smoothing_steps=10)\n",
    "\n",
    "# This can not be operated using VS code\n",
    "brain = stc_fsaverage.plot(**surfer_kwargs)\n",
    "\n",
    "for name in labels:\n",
    "    print(name)\n",
    "    brain.add_label(labels[name], borders=True)\n",
    "\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'???-lh'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method add_label in module surfer.viz:\n",
      "\n",
      "add_label(label, color=None, alpha=1, scalar_thresh=None, borders=False, hemi=None, subdir=None, **kwargs) method of surfer.viz.Brain instance\n",
      "    Add an ROI label to the image.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    label : str | instance of Label\n",
      "        label filepath or name. Can also be an instance of\n",
      "        an object with attributes \"hemi\", \"vertices\", \"name\", and\n",
      "        optionally \"color\" and \"values\" (if scalar_thresh is not None).\n",
      "    color : matplotlib-style color | None\n",
      "        anything matplotlib accepts: string, RGB, hex, etc. (default\n",
      "        \"crimson\")\n",
      "    alpha : float in [0, 1]\n",
      "        alpha level to control opacity\n",
      "    scalar_thresh : None or number\n",
      "        threshold the label ids using this value in the label\n",
      "        file's scalar field (i.e. label only vertices with\n",
      "        scalar >= thresh)\n",
      "    borders : bool | int\n",
      "        Show only label borders. If int, specify the number of steps\n",
      "        (away from the true border) along the cortical mesh to include\n",
      "        as part of the border definition.\n",
      "    hemi : str | None\n",
      "        If None, it is assumed to belong to the hemipshere being\n",
      "        shown. If two hemispheres are being shown, an error will\n",
      "        be thrown.\n",
      "    subdir : None | str\n",
      "        If a label is specified as name, subdir can be used to indicate\n",
      "        that the label file is in a sub-directory of the subject's\n",
      "        label directory rather than in the label directory itself (e.g.\n",
      "        for ``$SUBJECTS_DIR/$SUBJECT/label/aparc/lh.cuneus.label``\n",
      "        ``brain.add_label('cuneus', subdir='aparc')``).\n",
      "    **kwargs : additional keyword arguments\n",
      "        These are passed to the underlying\n",
      "        ``mayavi.mlab.pipeline.surface`` call.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    To remove previously added labels, run Brain.remove_labels().\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(brain.add_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
